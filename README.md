# MATEval
MATEval: A Multi-Agent Text Evaluation Framework

This paper has been ACCEPTED as a LONG PAPER presentation by DASFAA 2024 Industrial Track. You can currently access it through the following link: [MATEval](https://arxiv.org/abs/2403.19305)

In the Alipay business scenario, we need to assess open-ended story texts generated by large language models（LLMs）. For this specific business context, we have proposed a multi-agent evaluation framework called "MATEval". Within this framework, we have integrated strategies of self-reflection and Chain-of-Thought (CoT), and we have also introduced a feedback mechanism at the end of each round of discussion. This mechanism evaluates the quality of each discussion round, facilitating consensus. Ultimately, we require a summarizer to consolidate the results of the entire discussion process. We provide two formats of output: one in the form of Q&A pairs, and the other as text reports that are easy for humans to read. Extensive experiments demonstrate that MATEval's evaluation results on two classic story datasets are more aligned with human preferences compared to existing methods.

<img width="855" alt="image" src="https://github.com/AnonymousLYZYY/MATEval/assets/157742453/946a381a-9d2a-4e7e-a73d-4c90eadf3441">

<img width="1409" alt="image" src="https://github.com/liyu19980601/MATEval/assets/44581509/aa088ea1-4ea2-4e62-a617-5c0d3a5a005f">



In the MATEval framework, we select OpenAI’s GPT-4 as our LLMs due to its outstanding performance and API accessibility. We set the temperature parameter to 0 for result reproducibility. GPT-4’s easy access facilitated effective and coherent multi-agent interactions in our experiments.
<img width="1144" alt="image" src="https://github.com/liyu19980601/MATEval/assets/44581509/0d318d71-0110-4c86-836c-5a2d2f20b119">
